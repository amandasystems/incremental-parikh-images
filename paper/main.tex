\documentclass{easychair}

\usepackage{amsthm}
\usepackage{amssymb,amsmath,mathtools,empheq,fancybox}

\usepackage{paralist}
\usepackage{url}
\usepackage{color}

\usepackage{textcomp,listings}
\usepackage[backend=biber]{biblatex}
\usepackage{mymacros}

\usepackage{mathpartir}
\addbibresource{../bibliography.bib}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]


\newif\ifcomments
\commentstrue

\newcommand{\pr}[1]{{\color{red}``PR: #1''}}
\newcommand{\as}[1]{{\color{blue}``AS: #1''}}

\newif\ifoutline
\outlinetrue

\newcommand{\contents}[1]{\ifoutline{\color{blue}
    \begin{itemize}
    #1
    \end{itemize}
  }\fi}

\allowdisplaybreaks[1]

\title{An Efficient Calculus for Generalised Parikh Images of Regular Languages}
\author{some cool authors}
\institute{Uppsala University, Sweden}

\begin{document}
\maketitle

\begin{abstract}
  The image of the Parikh map is important in automata theory, offering a
  compact characterisation of an automaton. We contribute a novel understanding
  of how Parikh maps can be combined with arbitrary commutative monoid morphisms
  to efficiently represent a wide range of logics on automata and automata-like
  structures. Furthermore, we show how this formulation can be efficiently
  implemented as a calculus in a theorem prover supporting Presburger logic. In
  particular, our calculus allows us to solve the common problem in string
  solvers of computing the Parikh image of products of arbitrarily many
  automata. We demonstrate this by implementing a tool called \Catra{}, which we
  use to solve a set of constraints produced by \Fudge{the PyEx benchmarks} when
  solved by the \Ostrich{} string constraint solver. We show that this
  implementation in addition to having a lower memory footprint than the
  standard eager approach executed on the same underlying solver also
  outperforms the nuxmv model checker on the same problem\Fudge{, as well as the
  over-approximation recently described in~\cite{approximate-parikh}.}
\end{abstract}

\section{Introduction}

Parikh maps and their image appears naturally as part of many operations in model checking and the solving of string constraints in automata-based string solvers such as \Ostrich{}, notably in representing constraints on string lengths. While it is possible to compute the Parikh image of an automaton using the method described in \cite{generate-parikh-image}, this method produces large existentially quantified clauses which are costly to eliminate and in practice make many real-world problems intractable. Furthermore, applications to string analysis in theorem provers require symbolic labels to handle Unicode alphabets \Fudge{citation needed}. Conjunctions of string constraints finally, and most crucially, lead to the computation of Parikh images of automata products. Applying the approach in \cite{generate-parikh-image} would require the computation of the product before the Parikh image can be computed. In several instances we have observed, the materialisation of the product of the automata exhausts the memory of any reasonable machine due to the exponential blow-up of the product.

Addressing these concerns, our specialised calculus for Parikh images allows us to handle symbolic transition labels naturally, while also allowing us to interleave the computation of arbitrarily deep products of automata with the Parikh image of their product. This allows us to let both calculations inform each other, eliminating unnecessary work, and pruning the size of the partial products used in the computation. Moreover, the method can be used iteratively to, as it were, chew off bite-sized chunks of the product, thereby avoiding the problem of memory-outs.

\subsection{Motivating Example}

\section{Overview}

We define an non-deterministic automaton~$\Automaton$ with alphabet~$\Alphabet$
as $\Automaton = \AutomatonTuple$ where
$\Transitions = \States \times \Alphabet \times \States$, $\States$ is its
states, $\InitialState$ is w.l.o.g. assumed to be the single initial state, and
$\Accepting$ is its set of accepting states. Note that we will later generalise
the labels of transitions further.

\subsection{The Parikh Map of a Regular language}
Formally, the \textit{Parikh map} over a context-free language $\Strings=
\left\{a_1, \ldots, a_k \right\}$ is defined as in \cite{kozen}:

$$
\begin{aligned}
& \ParikhMap: \MapFromTo{\Strings}{\natural^k} \\
& \ParikhMap(s) = \left[\#a_1(s), \#a_2(s), \ldots, \#a_k(s)\right]
\end{aligned}
$$

That is, $\ParikhMap(s)$ is a vector of the number of occurrences of each
character in the language for a given string $s$. For example, for  $\Strings =
\Set{a, b}$, we would have $\ParikhMap(abb) = \VectorLiteral{1, 2}$.

We define the image of this map, the \textit{Parikh image}, of some subset of
the language $\Language \subseteq \Strings$ as:

$$
\ParikhMap(\Language) = \Set{\ParikhMap(x) \SuchThat x \in \Language}
$$

Thus we would have $\ParikhMap(\left\{ab, abb\right\}) = \left\{\left[1, 1\right],
\left[1, 2\right]\right\}$.

\subsection{The Parikh image of a regular language expressed in Presburger arithmetic}

Following~\cite{generate-parikh-image}, we define the Parikh Image of a regular
language recognised by a DFA $\Automaton = \AutomatonTuple$ as:

$$
\begin{aligned}
\psi(\mathcal{A}) := 
& \bigwedge_{\alpha \in \Sigma}
c_\alpha = \sum_{\delta \in \delta} t_\delta  
\text{ where $\alpha \in \delta$}\\
&\bigwedge_{q \in Q} \left (\text{$1$ if $q \in I$} +
\sum_{\delta = q' \xrightarrow{} q} t_\delta 
- \sum_{\delta = q\xrightarrow{}q'} t_\delta \right)
\begin{cases}
\geq 0 & \text{if $q \in I$} \\
= 0 & \text{ otherwise}
\end{cases}\\
& \bigwedge_{\delta = q \xrightarrow{} q'} t_\delta > 0 
\implies z_{'q} > 0 \\
& \bigwedge_{q, q' \in Q} z_{q'} > 0 
\implies 
\begin{cases}
\bigvee\limits_{\delta = q \xrightarrow{} q'} z_{q'} = z_{q} + 1 \land t_\delta > 0 \land z_{q} > 0 & \text{if $q \not\in  I$} \\
z_{q'} = 1 \land t_\delta > 0& \text{if $q \in I$}
\end{cases}
\end{aligned}
$$

where all variables $z_i, t_i$ are existentially quantified and the variables
$c_\alpha$ make up the actual image. Feeding this definition into a Presburger
solver and performing quantifier elimination on $z_i, t_i$ would produce the
Parikh image in its Presburger form. In this paper we use this example
(sometimes appropriately modified) as the baseline approach.

\subsubsection{An Example}

\Fudge{AN EXAMPLE!}

\subsection{Generalised Parikh Images}\label{sec:generalised}

To generalise the logic over Parikh images, we intrdouce a morphism $\Map:\: \Sigma
\to \Monoid$ where $\Monoid$ is a commutative monoid where the following holds:
\begin{itemize}
  \item $\Map(\epsilon) = 0$, where $0$ is the neutral element of $\Monoid$
  \item $\Map(a \Concat b) = \Map(a) + \Map(b)$
\end{itemize}

\subsubsection{Example~1: String length}

A useful example of such a morphism can express string length. We let $\Monoid =
\left(\mathbb{Z};+;0\right)$ and let $\Map(x) = 1$. Then the length of a string $s
= s_1 \RepeatSum{\Concat}  s_n$ is given by $\Map(s) = \sum \Map(s_i) = 1
\RepeatSum{+} 1$. Similarly, vectors and vector addition can be used to obtain
the regular Parikh map.

\Fudge{We also expect more efficient computation}

\subsubsection{Example~2: Parikh Automata}

\Fudge{We apply it to Parikh Automata and Magic Happens}

\subsection{Lazy Computation of Parikh Images for Regular Languages}

We assume an NFA $\Automaton = \AutomatonTuple$ with $\NrTransitions$
transitions $\Transitions =
\Set{\EllipsisSequence{\Transitions}{\NrTransitions}}$ where we describe each
such transition $\Transitions_i$ from state $\State$ to state $\State'$ with
label $\Label \in \Alphabet$ as $\Transitions_i =
\FromLabelTo{\State}{\Label}{\State'}$. When one or more of the states and
labels of a transition are uninteresting we will omit it.

For convenience, we introduce the following supporting concepts and notations:

\begin{definition}
  A \textit{path} $\Path = \PathEnumeration$ of an
  automaton $\Automaton$ represents a valid run of the automaton as a path
  starting in its initial state and taking zero or more transitions to arrive at
  a final accepting state $\State_n \in \Accepting$, while passing a number of labels
  $\Label_1, \ldots, \Label_n$. If $\InitialState \in \Accepting$, $\Tuple{\InitialState}$
  is a valid path.
  
  More formally, we require that:
  \begin{enumerate}
    \item $\forall_{k} \Transitions(\State_k, \Label_{k+1}, \State_{k+1})$
    \item $\State_n \in \Accepting$
  \end{enumerate}
\end{definition}

\begin{definition}
  The \textit{word} of a path $\WordOf(\Path) = \Label_1 \RepeatSum{\Concat} \Label_n$ is
  the word read out on its labels.
\end{definition}

\begin{definition}
 The \textit{transition count}, $\TransitionCount(\Transition, \Path)$ is the
 number of times a transition $\Transition =
 \FromLabelTo{\State_1}{\Label}{\State_2} \in \Transitions$ appears in a path
 $p$.
\end{definition}

We then introduce the two predicates into our calculus with the following
definitions:

\begin{definition}
  $\SinglePredicateInstance$ where:
  \begin{itemize}
    \item $\MonoidElement \in \Monoid$, for some commutative monoid $\Monoid$,
    as described in Section~\ref{sec:generalised}.
    \item $\Filter:\: \Transitions \to \Naturals$
  \end{itemize}
  holds when $\exists \Path = \PathEnumeration \in \Automaton$ such that:
  \begin{itemize}
    \item $\forall_{\Transition_i \in \Path} \Filter(\Transition_i) =
    \TransitionCount(\Transition_i, \Path)$
    \item $\WordOf(\Path) \in \Language(\Automaton)$
    \item $\MonoidElement = \Map(\WordOf(\Path))$
  \end{itemize}
\end{definition}

\begin{definition}
  $\Connected(\Automaton, \Filter)$ holds when
  $\exists \Path = \PathEnumeration \in \Automaton$ such that:
  \begin{itemize}
    \item $\forall_{\Transition_i \in \Transitions} \Filter(\Transition_i) = \TransitionCount(\Transition_i, \Path)$
    \item $\WordOf(p) \in \Language(\Automaton)$
  \end{itemize}

Intuitively, it represents the condition that $\Automaton$ is connected with
respect to the selection function $\Filter$. It is redundant to $\Image$ by
design.
\end{definition}


Finally, we present the rules of our calculus for one automaton. Note that we
operate on sets of symbols (terms, clauses). Additionally, we also use the
convention of splitting the terms into linear inequalities ($\SomeInequalities$)
and any other clauses ($\SomeClause$).

\begin{mathpar}
  \inferrule*[left=Expand]
  {\Connected(\Automaton, \Filter) \land \FlowEq(\Automaton, \Filter) \land \MonoidElement = \sum_{\Transition \in \Transitions} \Filter(\Transition) \cdot \Map(\Transition), \SomeInequalities, \SomeClause}
  {\SinglePredicateInstance, \SomeInequalities, \SomeClause}

  \inferrule*[left=Split, right=\textnormal{if $\Filter(\Transition) = 0 \not\in \SomeInequalities, \Filter(\Transition) > 0 \not\in \SomeInequalities$}]{\Connected(\Automaton, \Filter), \SomeInequalities, \SomeClause, \Filter(\Transition) = 0 \mid \Connected(\Automaton, \Filter), \SomeInequalities, \SomeClause, \Filter(\Transition) > 0}{\Connected(\Automaton, \Filter), \SomeInequalities, \SomeClause}

  \inferrule*[left=Propagate, right=\textnormal{if $\Filter(\Transition) = 0 \not\in\SomeInequalities, \forall \Path \in \Automaton \HoldsThat \exists c \in \Path \HoldsThat \Filter(c) = 0 \in \SomeInequalities $}]{\Connected(\Automaton, \Filter), \SomeInequalities, \SomeClause, \Filter(\Transition) = 0}{\Connected(\Automaton, \Filter), \SomeInequalities, \SomeClause}

  \inferrule*[left=Subsume, right=\textnormal{if $\forall \Transition = \FromLabelTo{s_0}{}{s_1} \in \Transitions, \Filter(\Transition) = 0 \not \in \SomeInequalities \HoldsThat \exists \Path \in \Automaton, s_0 \in \Path \HoldsThat \forall c \in \TransitionsOf(\Path) \HoldsThat \Filter(c) > 0 \in \SomeInequalities$}]{\SomeInequalities,\SomeClause}{\Connected(\Automaton, \Filter), \SomeInequalities, \SomeClause}
\end{mathpar}

We use the pseudo-function $\FlowEq(\Automaton, \Filter)$ that generates a set
of existentially quantified linear inequalities with the following definition:
$$
\begin{aligned}
  & \FlowEq(\Automaton, \Filter) = \AndComp{\State \in \States}{\In(\State, \Filter) - \Out(\State, \Filter)}
\text{ $\geq 0$ if $\State \in \Accepting$, $= 0$ otherwise}\\
  & \In(\State, \Filter) = \left(\text{$1$ if $\State = \InitialState$, otherwise $0$}\right) + \sum_{\Transition = \FromLabelTo{\State_0}{}{\State} \in \Transitions} \Filter(\Transition)\\
  & \Out(\State, \Filter) = \sum_{\Transition = \FromLabelTo{\State}{}{\State'} \in \Transitions} \Filter(\Transition)
\end{aligned}
$$
Where we transparently assign fresh variables to each state $\State \in \States$
and existentially quantify them in the whole clause.

Additionally, we assume the existence of a rule \PresburgerClose{},
corresponding to a sound and complete solver for Presburger formulae, modulo the
monoid~$\Monoid$.

The $\Propagate{}$ rule allows us to propagate (dis-)connectedness across
$\Automaton$. It states that we are only allowed to use transitions attached to
a reachable state, and is necessary to ensure connectedness in the presence of
cycles in~$\Automaton$.

\textsc{Expand} expands the predicate into its most basic rules; one set of
linear equations synchronising the transitions mentioned by $\Filter$ to the
corresponding Monoid element~$\MonoidElement$, and the linear flow equations of
the standard Parikh image formulation, as described by~\FlowEq. Since
$\Connected$ and $\Image$ are partially redundant and the difference is covered
by~$\FlowEq$, we can remove the instance of~$\Image$ when applying~$\Expand$. In
this sense, we split the semantics of the $\Image$~predicate into its counting
aspect (covered by $\FlowEq$) and its connectedness aspect (covered by
$\Connected$).

Finally, $\Split{}$ allows us to branch the proof tree by trying to exclude a
contested transition from a potential solution before concluding that it must be
included. Intuitively, this is what guarantees our ability to make forward
progress by eliminating paths through~$\Automaton$.

A decision procedure for our predicate in a tableau-based automated theorem
prover would start by expanding the predicate using the $\Expand{}$~rule.
If~$\Automaton$ contains no loops that could be disconnected from a minimum
spanning tree (MST) with its root in~$\InitialState$, the initial state, this
would be sufficient to reach subsumption immediately.

\subsection{An Example}

\section{Parikh Images from Products of Automata}
  
\contents{
    \item additional rules needed for products
    \item backjumping and conflict-driven learning
    }

% To generalise the calculus to calculations on products of automata, we change the main predicate take arbitrarily many automata:
% \begin{definition}
%   $\ProductPredicateInstance$ is true exactly when:
%   \begin{itemize}
%   \item $h:\: \Alphabet^* \rightarrow \SomeMonoid$, a morphism to a commutative product monoid $\SomeMonoid = \prod_{i} \SomeMonoid_i$.
%   \item $\MonoidElement$ is a vector of elements of $\SomeMonoid$.
%   \item $\AutomatonVector$ is a vector of automata.
%   \item $\Automaton = \prod_{i} \AutomatonVector_i$
%   \item each $\TransitionVec_i$ is a vector of terms such that each term correspond to a
%     transition in $\AutomatonVector_i$, and $\TransitionVectors$ is a vector of those vectors. We use the terminology $\TransitionTerm(t)$ to refer to the term of the transition vector for a given transition $t$.
%   \item $y = \sum_{t \in \Transitions} h(t)$
%   \item $\SourceTransitions(\Automaton, t)$ is the set of transitions from the
%   term automata used to produce the transition $t$ in the product automaton
%   $\Automaton$.
%   \end{itemize}
%   \end{definition}

%   First we extend $\Expand$ to generate flow equations and instances of $\Connected$ for each automaton:
%   \begin{mathpar}
%     \inferrule*[left=Expand]
%       {\AndComp{\Automaton_i \in \AutomatonVector}{\FlowEq(\Automaton_i) \land \Connected(\Automaton_i)}\ldots}
%       {\ProductPredicateInstance \land \SomeClause}
%   \end{mathpar}

%   %  x(t) = sum(e : termProductEdges(t, default=0))
% Then we introduce the rule $\Materialise$, used to compute a partial product between two terms $\Automaton_i, \Automaton_j$:
% \begin{mathpar}
%   \inferrule*[left=Materialise, 
%   right=\textnormal{where $\Automaton_{k} = \Automaton_i \times \Automaton_j, \AutomatonVector' = (\AutomatonVector \cup \{  \Automaton_k \}) \setminus {\Automaton_i, \Automaton_j}$}]
%     {\AndComp{t \in \delta(\Automaton_{k})}{\TransitionTerm(t) = \sum_{t' \in \SourceTransitions(t, \Automaton_k)} t'}\\
%     \FlowEq(\Automaton_{k}) \land \Connected(\Automaton_{k}) \land
%     \\ \MonoidMap(\AutomatonVector', \TransitionVectors', \MonoidElement) \land \SomeClause} {\MonoidMap(\AutomatonVector, \TransitionVectors, \MonoidElement) \land \SomeClause}
% \end{mathpar}

% Note that we implicitly existentially quantify the fresh transition terms $\TransitionVec_{k+1}$ for the product.

% $\Materialise$ comes with its companion rule $\RemoveTermConnected$ that simply
% states we are allowed to remove any instances of $\Connected$ from terms that
% have been used in a product, and whose connectedness we therefore no longer care about:
% \begin{mathpar}
%   \inferrule*[left=$\RemoveTermConnected$, right=\textnormal{If $\Automaton_a$ not in $\Automaton_1\ldots\Automaton_k$}]
%     {\ProductPredicateInstance \land \SomeClause}
%     {\Connected(\Automaton_a) \land \ProductPredicateInstance \land \SomeClause}
% \end{mathpar}

% Finally, we add a side condition to $\Subsume$ to only allow subsumption for
% instances of $\MonoidMap$ with just one automaton, ensuring that we do not bail
% out before having computed the entire product.

\subsection{An Example}

\subsection{The calculus is correct}

To be as clear as possible about what it means for our calculus to be correct,
we use more exact definitions than the traditional soundness and completeness.

\subsubsection{The calculus terminates}
\subsubsection{The calculus allows no values outside the Parikh image}
\subsubsection{The calculus allows all values in the Parikh image}

\section{Extending and generalising the calculus}

\section{Implementation and Experiments}

\contents{
\item length constraints
\item Parikh automata, automata with registers
\item Model-checking examples
}

\section{Conclusions}

\clearpage
%\bibliographystyle{splncs03}
\printbibliography

\end{document}
