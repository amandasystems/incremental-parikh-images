We first survey some of the required background on finite-state
automata and the Parikh image. In addition, we assume basic familiarity
with first-order logic, Presburger
arithmetic, and the classical sequent calculus; for reference, see
e.g. \cite{Fitting96a}.

\subsection{Monoids}

% AS: reviewer comment #54 complains that this is basic, are they right?

% PR: sure, this is rather basic; but I think we should still include
% those definitions

A monoid $\Monoid = \Tuple{X;\MonoidOp;0_{\Monoid}}$ is an algebraic structure
consisting of the non-empty carrier set of elements, $X$; an associative binary operation
$X \times X \rightarrow X$ denoted as $\MonoidOp$, that is where for all $a, b,
c \in X$, $(a \MonoidOp b) \MonoidOp c = a \MonoidOp (b \MonoidOp c)$; 
and an identity element $0_{\Monoid} \in X$ such that
$0_{\Monoid} \MonoidOp a = a \MonoidOp 0_{\Monoid} =   a$ for every $a \in X$.
We sometimes use integer multiplication to represent a repeated application of
$\MonoidOp$, e.g. $3a = a \MonoidOp a \MonoidOp a$, for $a \in X$. $\Monoid$ is
called \textit{commutative} if $\MonoidOp$ also commutes, that is if $a
\MonoidOp b = b \MonoidOp a$ for all $a, b \in X$. 

A \textit{homomorphism} is a structure-preserving map between two
monoids $\Monoid = \Tuple{X;\MonoidOp;0_{\Monoid}}$ and
$\Monoid' = \Tuple{X';\MonoidOp';0_{\Monoid'}}$, that is a map
$\Map : X_1 \rightarrow X_2$ such that
$\Map(a \MonoidOp b) = \Map(a) \MonoidOp' \Map(b)$ and
$\Map(0_{\Monoid}) = 0_{\Monoid'}$.

\subsection{Languages, Finite-state Automata and their Products}
\label{sec:languages}

We define an alphabet as a finite set of symbols $\Alphabet$ with words $\Strings$, and
the concatenation operation as $s_1 \Concat{} s_2$ over two strings $s_1, s_2$.
Note that $\Strings = \Tuple{\Alphabet;\Concat{};\epsilon}$, is a
non-commutative monoid, referred to as the free monoid on $\Alphabet$.
The string length
function, $\Length{s}$ is an example of a homomorphism between $\Strings$
and~$\mathbb{Z}$.

A \emph{finite-state automaton}~$\Automaton$ with alphabet~$\Alphabet$ is a
tuple~$\AutomatonTuple$, where $\States$ is the set of states,
$\InitialState$ the initial state, $\AcceptingStates$ the set of
accepting states, and
$\Transitions \subseteq \States \times \Alphabet \times \States$ the
transition relation.  We write a transition
$\Transition = \Tuple{\State, \Label, \State'} \in \Transitions$ as
$\Transition = \FromLabelTo{\State}{\Label}{\State'}$.  Similarly, we
use the notation $\FromLabelTo{\State}{}{}$ to refer to the set of
transitions starting in $\State$, and $\FromLabelTo{}{}{\State}$ to
refer to the set of transitions coming into $\State$, whenever the
automaton is clear from the context.

We will let variables $\Transition, \Transition', \Transition_1, \ldots,
\Transition_n$, etc., denote transitions, $\State, \ldots, \State_n$ states, and
$\Automaton, \ldots, \Automaton_n$ automata, and use subscript indexing
($\Transitions_\Automaton$) to refer to the transitions, states, etc., of a given
automaton.

A \textit{path} $\Path = \PathEnumeration$ of an
automaton~$\Automaton$ is a sequence of
states~$\State_0, \ldots, \State_n$ interleaved with
letters~$\Label_1, \ldots, \Label_n$ such that
$\State_0 = \InitialState$ and
$\FromLabelTo{\State_{i-1}}{\Label_{i}}{\State_{i}}$ for
$i \in \{1, \ldots, n\}$.  The path is \emph{accepting} if the end
state is accepting, $\State_n \in \AcceptingStates$. The \textit{set
  of paths} of $\Automaton$ is denoted by
$\Paths(\Automaton)$. Additionally, we use the
notation~$\Paths(\Automaton, \State)$ to mean all paths ending in
state~$\State$. We write $\Transition \in \Path$ to express that
transition~$\Transition$ occurs on path~$\Path$. The \textit{states} of a path
$\Path = \PathEnumeration$, denoted
$\StatesOf(\Path) = \Set{\State_0\RepeatSum{,} \State_n}$ are the
states visited along $\Path$. Note that
$\InitialState \in \StatesOf(\Path)$ for every path since all paths
start in the initial state.  The \textit{word} of a path
$\Path = \PathEnumeration$ is the word
$\WordOf(\Path) = \Label_1 \RepeatSum{\Concat}
 \Label_n \in \Strings$ formed by the labels on the path. Finally, the
 set of words accepted by an automaton~$\Automaton$, denoted by
 $\Language(\Automaton) \subseteq \Strings$, is the set of words of
 accepting paths.

The \emph{product} of two
automata~$\Automaton_1 = \Tuple{\States^1, \InitialState^1,
  \AcceptingStates^1, \Transitions^1}$ and
$\Automaton_2 = \Tuple{\States^2, \InitialState^2,
  \AcceptingStates^2, \Transitions^2}$ is the automaton
\begin{align*}
\Automaton_1 \times \Automaton_2 &=
\Tuple{\States_1 \times \States_2, \STuple{\InitialState^1, \InitialState^2},
\AcceptingStates^1 \times \AcceptingStates^2,
  \Transitions}\\
  \text{with}\quad \Transitions &= \{\STuple{\STuple{q,q''}, l, \STuple{q',q'''}} \mid \STuple{q, l, q'} \in \Transitions^1, \STuple{q'', l, q'''} \in \Transitions^2\}~.
\end{align*}
The product automaton runs $\Automaton_1$ and $\Automaton_2$ in
parallel on an input and only accepts the input if both automata would
do so; we have $\Language(\Automaton_1 \times \Automaton_2) =
\Language(\Automaton_1) \cap \Language(\Automaton_2)$.

\subsection{The Parikh Map and its Image}
Formally, the \textit{Parikh map} over an alphabet $\Alphabet=
\left\{a_1, \ldots, a_k \right\}$ is defined as in \cite{kozen}:
$$
\begin{aligned}
& \ParikhMap: \MapFromTo{\Strings}{\natural^k} \\
& \ParikhMap(s) = \VectorLiteral{\#a_1(s), \#a_2(s), \ldots, \#a_k(s)}
\end{aligned}
$$

That is, $\ParikhMap(s)$ is a vector of the number of occurrences of each
character in the language for a given string $s$. For example, for  $\Alphabet =
\Set{a, b}$, we would have $\ParikhMap(abb) = \VectorLiteral{1, 2}$.

We define the image of this map, the \textit{Parikh image}, of some
language $\Language \subseteq \Strings$ as:
\[
\ParikhMap(\Language) = \Set{\ParikhMap(x) \SuchThat x \in \Language}
\]

Thus, we would have $\ParikhMap(\left\{ab, abb\right\}) = \left\{\left[1,
1\right], \left[1, 2\right]\right\}$. We also sometimes use the standard
notation $\CountOf{l}(w)$ to talk about an individual letter $l$ in a word $w$. For
example, for the Parikh vector above, we would have $\CountOf{a}(abb) = 1$.

% AS: Reviewers suggest we drop this:
% PR, shortened a bit
Parikh's theorem states that any context-free language has a Parikh-equivalent
regular language (c.f.~\cite{construction} for a construction of such automata
from context-free grammars and~\cite{bounds} for bounds on its size).
The Parikh image is therefore a semi-linear set and Presburger-definable.
%However,
%there are languages that are not context-free that also have semilinear images
%under~$\ParikhMap$ (e.g. $\ParikhMap(\Set{a^nb^nc^n \SuchThat n \geq 0}) =
%\ParikhMap((abc)^*) = \CountOf{a} = \CountOf{b} = \CountOf{c} \land \CountOf{a}
%\geq 0$). This means they can be represented as a quantifier-free Presburger
%formula.
%
While Parikh's theorem applies to arbitrary context-free languages, in this
paper we focus only on regular languages.

\subsection{The Parikh image of a regular language expressed in Presburger arithmetic}
\label{sec:verma}

It is known that the Parikh image of any context-free language can be
described by a linear-size existential Presburger
formula~\cite{generate-parikh-image}. This representation can be
straightforwardly adapted for use with a product of regular
languages. For an intuition, the approach consists of first computing
the product, then assigning each state and transition an existentially
quantified non-negative integer variable, and then describing all
paths through the automaton through two sets of constraints: flow
equations relating the inflow and outflow of each automaton state, and
constraints that enforce connectedness by ordering states by distance
in a spanning tree rooted in the initial state.

We refer to this model as the baseline approach, though we also apply
optimisations as described in \cref{sec:implementing-baseline}. The calculus
introduced in this paper, by contrast, lazily enforces the connectedness
constraint while also interleaving the computation of products of automata and
propagating information between the steps to reduce the amount of work that
needs to be done.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "main"
%%% End:
