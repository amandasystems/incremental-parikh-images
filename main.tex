%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[acmsmall,review,anonymous,screen]{acmart}\settopmatter{printfolios=true,printccs=true,printacmref=true}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[acmsmall,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[acmsmall]{acmart}\settopmatter{}


%% Journal information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmJournal{PACMPL}
\acmVolume{1}
\acmNumber{POPL} % CONF = POPL or ICFP or OOPSLA
\acmArticle{1}
\acmYear{2023}
\acmMonth{1}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2018}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%% Note: author/year citations are required for papers published as an
%% issue of PACMPL.
\citestyle{acmauthoryear}   %% For author/year citations


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from PACMPL format to traditional
%% SIGPLAN proceedings format must update the '\documentclass' and
%% topmatter commands above; see 'acmart-sigplanproc-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption



\usepackage{amsmath,empheq,fancybox}
\usepackage{paralist}
\usepackage{url}
\usepackage{color}
\usepackage{textcomp,listings}
\usepackage{array}
\usepackage{mymacros}
\usepackage{microtype}
\usepackage{listings}
\usepackage{csquotes}
\usepackage{proof}
\usepackage[capitalise]{cleveref}
\usepackage{algorithm2e}      
\usepackage{multirow}
\usepackage{mathpartir}
\usepackage{amsthm}
\usepackage{numprint}
\usepackage{ebproof}
\usepackage[makeroom]{cancel}

\usepackage{mathtools} % Bonus

\usepackage{enumitem}


\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}{Example}[section]

\newlist{constraints}{enumerate}{3}
\setlist[constraints,1]{%
    label=\sffamily{(\roman*):},
    ref=\normalfont{Constraint (\roman*)},
    wide,itemsep=0pt,topsep=0pt
}    
\crefname{constraintsi}{}{}
\Crefname{constraintsi}{}{}


\lstset{
    columns=fullflexible,
    showspaces=false,
    showtabs=false,
    breaklines=true,
    showstringspaces=false,
    breakatwhitespace=true,
    escapeinside={(*@}{@*)},
    commentstyle=\color{greencomments},
    keywordstyle=\color{bluekeywords},
    stringstyle=\color{redstrings},
    numberstyle=\color{graynumbers},
    basicstyle=\ttfamily\small,
    framesep=12pt,
    xleftmargin=12pt,
    tabsize=4,
    captionpos=b
}


\newif\ifcomments%
\commentstrue%
\newif\ifoutline%
\outlinetrue{}

\newcommand{\contents}[1]{\ifoutline{\color{blue}
    \begin{itemize}
    #1
    \end{itemize}
  }\fi}

\allowdisplaybreaks[1]


\begin{document}

%% Title information
\title{A Constraint Solving Approach to Parikh Images of Regular Languages}
                                        %% when present, will be used in
                                        %% header instead of Full Title.
%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with single affiliation.
\author{First1 Last1}
\authornote{with author1 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position1}
  \department{Department1}              %% \department is recommended
  \institution{Institution1}            %% \institution is required
  \streetaddress{Street1 Address1}
  \city{City1}
  \state{State1}
  \postcode{Post-Code1}
  \country{Country1}                    %% \country is recommended
}
\email{first1.last1@inst1.edu}          %% \email is recommended

%% Author with two affiliations and emails.
\author{First2 Last2}
\authornote{with author2 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{Position2a}
  \department{Department2a}             %% \department is recommended
  \institution{Institution2a}           %% \institution is required
  \streetaddress{Street2a Address2a}
  \city{City2a}
  \state{State2a}
  \postcode{Post-Code2a}
  \country{Country2a}                   %% \country is recommended
}
\email{first2.last2@inst2a.com}         %% \email is recommended
\affiliation{
  \position{Position2b}
  \department{Department2b}             %% \department is recommended
  \institution{Institution2b}           %% \institution is required
  \streetaddress{Street3b Address2b}
  \city{City2b}
  \state{State2b}
  \postcode{Post-Code2b}
  \country{Country2b}                   %% \country is recommended
}
\email{first2.last2@inst2b.org}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
  A common problem in string constraint solvers is computing the Parikh image, a
   set of linear equations that describe all possible combinations of character
   counts in strings of a given language. Automata-based string solvers
   frequently need to compute the Parikh image of large products (intersections)
   of nondeterministic automata, which in many operations is both prohibitively
   slow and memory-intensive. We contribute a novel understanding of how Parikh
   maps can be tackled as a constraint solving problem to solve real-world
   constraints stemming from functions on regular languages, most notably the
   length constraint. Furthermore, we show how this formulation can be
   efficiently implemented as a calculus, \Calculus{}, in an automated theorem
   prover supporting Presburger logic.  We implement \Calculus{} in a tool
   called \Catra{}, and evaluate it on constraints produced by the
   \OstrichPlus{} string constraint solver when solving Parikh automata
   intersection problems produced when solving standard string constraint
   benchmarks involving string length constraints. We show that our solution
   strictly outperforms the standard approach described
   in~\citeauthor{generate-parikh-image} as well as the over-approximating
   method recently described by~\citeauthor{approximate-parikh} by a wide
   marigin, and for realistic timeouts for constraint solving also the~\Nuxmv{}
   model checker.
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
  <ccs2012>
  <concept>
  <concept_id>10003752.10003766.10003773.10003775</concept_id>
  <concept_desc>Theory of computation~Quantitative automata</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10003766.10003776</concept_id>
  <concept_desc>Theory of computation~Regular languages</concept_desc>
  <concept_significance>300</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10003790.10003794</concept_id>
  <concept_desc>Theory of computation~Automated reasoning</concept_desc>
  <concept_significance>500</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10010124.10010138.10010142</concept_id>
  <concept_desc>Theory of computation~Program verification</concept_desc>
  <concept_significance>300</concept_significance>
  </concept>
  <concept>
  <concept_id>10003752.10003790.10011192</concept_id>
  <concept_desc>Theory of computation~Verification by model checking</concept_desc>
  <concept_significance>300</concept_significance>
  </concept>
  </ccs2012>  
\end{CCSXML}

\ccsdesc[500]{Theory of computation~Quantitative automata}
\ccsdesc[300]{Theory of computation~Regular languages}
\ccsdesc[500]{Theory of computation~Automated reasoning}
\ccsdesc[300]{Theory of computation~Program verification}
\ccsdesc[300]{Theory of computation~Verification by model checking}
%% End of generated code


%% Keywords
%% comma separated list
\keywords{Parikh images, string solvers, model checking}  %% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle


\section{Introduction}\label{sec:introduction}
\input{introduction.tex}

\section{An Intuition for Our Approach}\label{sec:intuition}
\input{example.tex}

\section{Preliminaries}\label{sec:preliminaries}
\input{preliminaries.tex}

\section{Projections on Parikh Images}\label{sec:generalised}
\input{generalised.tex}

\section{A Calculus for Projections on Parikh Images}\label{sec:calculus}
\input{calculus.tex}

\section{Parikh Images from Products of Automata}\label{sec:multiple}
\input{multiple.tex}


\section{Extensions}\label{sec:extensions}
\input{extensions.tex}

\section{Implementation}\label{sec:implementation}

We implement \Calculus{} for Parikh automata as described in
\cref{sec:parikh-automata}. The artefact submitted along with this paper is a
program that reads an instance file with one or more products of one or more
Parikh automaton with transition labels defined as ranges of Unicode characters,
along with a set of constraints on the final values of their registers expressed
as Presburger arithmetic in a C-like syntax. We call this program
\Catra.
% \footnote{If you really must read it as an acronym, please read it as
%CAtegory Theory on Register Automata, or if you object to the somewhat
%nonstandard use of register automata and category theory, as Check Assignments
%of The Registers Afterwards. Or alternatively if you find it all to be too much
%of a theoretical exercise, as Can Anyone Think of A Real Application.}

\Catra{} is written in Scala, with the calculus described in this paper
implemented as a theory plug-in for the \Princess{} automated theorem
prover~\cite{princess}, which also performs the Presburger reasoning. For
comparison, we also provide an implementation of the baseline method
from~\cite{generate-parikh-image}, a direct translation that uses the~\Nuxmv{}
symbolic model checker~\cite{nuxmv} to solve our constraints, and the
approximation described in~\cite{approximate-parikh} on top of the standard
baseline back-end. An example of an input file corresponding to our running
example introduced in \cref{sec:motivation} can be seen in
\cref{lst:input-example}.

\Catra{} uses symbolic labels for automata. A symbolic label is defined as a
finite range of Unicode code points. This allows succinct representation of many
regular expression patterns such as \lstinline{(a-z).*} which would have
otherwise required $27$~transitions. The transition for the range would be
written \lstinline{a -> b [97, 122]}.

In satisfaction mode, supported by all backends, \Catra{} tries to satisfy the
constraints expressed by the input file, reporting \Sat{} with register
assignments or \Unsat{} much like traditional~SAT- or SMT solvers would.
Additionally, baseline and \Calculus{} also support generation of the Presburger
formula describing the constraints of the input file. Baseline uses standard
quantifier elimination, and \Calculus{} uses the method described in
\cref{sec:finding-the-image}.

Since \Princess{} does not support multiple-arity predicates like the ones we
use in \Calculus{}, we have implemented variable-length arguments using
additional helper predicates. These are $\Unused{}(\Automaton)$, which marks an
automaton as unused in any product, and $\TransitionMask{}(\Automaton,
\Transition, \Filter(\Transition))$ which associates a transition $\Transition$
and automaton $\Automaton$ with its corresponding transition variable.
Additionally, we associate each of our predicates with an instance variable in
order to differentiate instances of the predicates.

\subsection{Implementing the Baseline}\label{sec:implementing-baseline}

We baseline using the same Presburger solver (\Princess{}), input file parser,
and automaton implementation as \Catra. We do this in order to better analyse
the impact of the calculus rules themselves. Using the formula of
\eqref{eq:generate-parikh}, we produce quantified Presburger formulae for each
successive term and add them to \Princess. We compute the product incrementally
term by term, checking satisfiability at each step. We use a priority queue to
select automata for each step, and order it by the number of transitions as a
heuristic for the size of the automata. We use this heuristic to avoid computing
large (and therefore slow) products until we have to, banking our hopes on
computing an empty intermittent product early.

\begin{algorithm}
  \caption{How we implement the baseline approach}\label{alg:baseline}
  \KwData{$\Automaton_1, \ldots, \Automaton_n$ automata, other constraints $\SomeClause$}
  \KwResult{\textsc{Sat} or \textsc{Unsat}}
  \SetKwFunction{NewTheoremProver}{newTheoremProver}
  \SetKwFunction{NewPriorityQueue}{newPriorityQueue}
  \SetKwFunction{Dequeue}{dequeue}
  \SetKwFunction{Enqueue}{enqueue}
  \SetKwFunction{Assert}{assert}

  $p \gets \NewTheoremProver{}$

  \Assert{$p$, $\SomeClause$}

  \ForEach{$\Automaton_i$}{
    \Assert{$p, \ParikhMap(\Automaton_i)$}

    \If{$p$ is \textsc{Unsat}}{break}

  }

  $q \gets \NewPriorityQueue{}$


  \While{$p$ not \textsc{Unsat} and $|q| > 1$}{
    $\Automaton, \Automaton' \gets \Dequeue{q}$ 
    
    \Assert{$p, \ParikhMap(\Automaton \times \Automaton')$}

    \Enqueue{$q, \Automaton \times \Automaton'$}
  }
  
  \KwRet{$p$'s SAT status}

  \end{algorithm}

As an optimisation, our automata (including intermittent products) are created
forward- and backward- reachable-minimal. Any automaton we produce only contains
states that are both reachable from the initial state and has a path to an
accepting state. We never perform any other minimisation on the automata for
either backend. More complex minimisation was left out since performing
minimisation on automata with counters is non-trivial, and minimising symbolic
automata risks exponential blowup \cite{minimising-symbolic}.

\subsection{Heuristics and search strategies}

There are a number of choices left unspecified in \Calculus{} as described in
\cref{sec:calculus,sec:multiple}. For example, the order of materialisation of
intermediate products and the order of splitting. In this section we describe
additional implementation details and techniques used to enhance \Catra.

\subsubsection{Splitting, Materialisation, and Propagation}

We order our rule applications so that we first propagate connectedness if
possible, then perform materialisation if tractable as defined below, then
finally resort to splitting if we must.

In addition to applying \Split{} as described in \cref{tbl:rules:single} to
randomly selected transitions, we prefer splitting to sever a strongly connected
from the initial state. We randomly select an automaton where we can compute a
cut between an SCC and the initial state, that is where the SCC does not contain
the initial state and where the sum of the transition variables of the
transitions in the cut is not known to be positive. If there are multiple such
strongly connected components we choose one randomly. We then proceed to split
on the sum of the transition variables of the cut as if it were a regular
transition, e.g. its sum being zero or nonzero. In this way we drive \Calculus{}
towards applying \Propagate{}.

The implementation of the connectedness constraint is opportunistic and straightforward. We compute a set of dead states by performing forward and backwards reachability computations on an automaton, where we disregard any transition whose associated variable is known to be zero. After that we add clauses ensuring any transition variable associated with a transition starting in a dead state is zero.

Product materialisation is the final piece of the puzzle. In the current
implementation we put off computing intermediate products until at least all but
two transition variables of one of the automata is known to be either present or
absent. The number was chosen experimentally, and we observe a consistent trend
towards lower numbers being better. The other automaton for the product is
selected randomly.

\subsubsection{Clause Learning}

\Catra{} enables clause learning by default when using our backend, as it has
been experimentally shown to increase the performance in aggregate (though not
strictly). We do not currently implement all the proposed features of
\cref{sec:ext:backjumping}, but we do implement forward-reachability cut
learning. No sophisticated clause learning for products has been implemented.

\subsubsection{Random Restarts}

Finally, we perform restarts scaled by the Luby series~\cite{luby}. Experimental
results have shown this to have a large improvement in performance, which is
unsurprising given how many random choices we make during solving and how
tail-heavy our problem is.

\section{Evaluation}\label{sec:experiments}
\input{evaluation.tex}

\section{Conclusion}

In this paper we have introduced a calculus to compute commutating operations on
intersections of regular languages that we call \Calculus{}. We have evaluated
it on \NrBenchmarks{} Parikh automata intersection problems generated by the
\OstrichPlus{} string solver \cite{ostrich-plus} solving the PyEx benchmark
suite \cite{pyex} using our Parikh automata solver \Catra{}.

Within \Catra{}, \Calculus{} shows astonishing performance in terms of memory
usage and solve-time compared to the baseline approach laid out in
\cite{generate-parikh-image} when implemented on the same underlying automated
theorem prover (\Princess{}, \cite{princess}). It is also competitive with the
\Nuxmv{} model checker \cite{nuxmv}, outperforming it on unsatisfiable instances
and generally outperforming it for timeouts under 30 seconds with its advantage
increasing drastically for even shorter timeouts. 30 seconds would generally be
considered a long timeout for our intended use as supporting infrastructure to a
string constraint solver.

Future investigations involve two tracks. The first one is integration into
existing string solvers (wich \Ostrich{} being a particularly promising
candidate due to its shared use of \Princess{}), and further adaptation to that
use case. Closer inspection of the instances where we currently time out should
be useful to further improve our heuristics.

The second track for future improvements is the extension into other problem
domains, including other logics, model checking problems, as well as to more
powerful automata such as transducers. In principle, we are also already able to
express stronger constraints than Parikh automata, due to our use of a full
automated theorem prover which allows adding arbitrary constraints in addition
to the expected Presburger formulae.

%% Acknowledgments
% \begin{acks}                            %% acks environment is optional
%                                         %% contents suppressed with 'anonymous'
%   %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
%   %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
%   %% acknowledge financial support and will be used by metadata
%   %% extraction tools.
%   This material is based upon work supported by the
%   \grantsponsor{GS100000001}{National Science
%     Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
%   No.~\grantnum{GS100000001}{nnnnnnn} and Grant
%   No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
%   conclusions or recommendations expressed in this material are those
%   of the author and do not necessarily reflect the views of the
%   National Science Foundation.
% \end{acks}


%% Bibliography
\bibliography{bibliography}


%% Appendix
\appendix
\section{Appendix}
\input{appendix.tex}
\end{document}
